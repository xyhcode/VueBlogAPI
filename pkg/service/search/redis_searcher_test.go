package search

import (
	"strings"
	"testing"
	"time"
)

func TestTokenize(t *testing.T) {
	tests := []struct {
		name     string
		input    string
		expected []string
	}{
		{
			name:     "ç©ºå­—ç¬¦ä¸²",
			input:    "",
			expected: []string{},
		},
		{
			name:     "çº¯ç©ºæ ¼",
			input:    "   \t\n  ",
			expected: []string{},
		},
		{
			name:     "çº¯è‹±æ–‡",
			input:    "Hello World",
			expected: []string{"hello", "world"},
		},
		{
			name:     "çº¯ä¸­æ–‡",
			input:    "ä½ å¥½ä¸–ç•Œ",
			expected: []string{"ä½ ", "å¥½", "ä¸–", "ç•Œ", "ä½ å¥½", "å¥½ä¸–", "ä¸–ç•Œ"},
		},
		{
			name:     "ä¸­è‹±æ–‡æ··åˆ",
			input:    "Hello ä¸–ç•Œ World",
			expected: []string{"hello", "world", "ä¸–", "ç•Œ", "ä¸–ç•Œ"},
		},
		{
			name:     "åŒ…å«HTMLæ ‡ç­¾",
			input:    "<h1>Hello</h1> <p>ä¸–ç•Œ</p>",
			expected: []string{"h1", "hello", "p", "ä¸–", "ç•Œ", "ä¸–ç•Œ"},
		},
		{
			name:     "åŒ…å«ç‰¹æ®Šå­—ç¬¦",
			input:    "Hello@World#ä¸–ç•Œ$",
			expected: []string{"hello", "world", "ä¸–", "ç•Œ", "ä¸–ç•Œ"},
		},
		{
			name:     "åŒ…å«æ•°å­—ï¼ˆå†…å®¹ä¸­ï¼‰",
			input:    "Hello 123 World 456",
			expected: []string{"hello", "123", "world", "456"},
		},
		{
			name:     "åŒ…å«æ ‡ç‚¹ç¬¦å·",
			input:    "Hello, World! ä½ å¥½ï¼Œä¸–ç•Œï¼Ÿ",
			expected: []string{"hello", "world", "ä½ ", "å¥½", "ä¸–", "ç•Œ", "ä½ å¥½", "ä¸–ç•Œ"},
		},
		{
			name:     "å¤§å°å†™æ··åˆ",
			input:    "Hello WORLD hElLo",
			expected: []string{"hello", "world"}, // æ–°é€»è¾‘ä¼šå»é‡
		},
		{
			name:     "é‡å¤è¯",
			input:    "Hello Hello World World",
			expected: []string{"hello", "world"},
		},
		{
			name:     "å•ä¸ªå­—ç¬¦",
			input:    "a b c",
			expected: []string{"a", "b", "c"},
		},
		{
			name:     "Unicodeå­—ç¬¦",
			input:    "Hello ğŸŒ ä¸–ç•Œ",
			expected: []string{"hello", "ä¸–", "ç•Œ", "ä¸–ç•Œ"},
		},
		{
			name:     "ç‰ˆæœ¬å·",
			input:    "Go 1.18.0",
			expected: []string{"go", "1.18.0"},
		},
		{
			name:     "å¸¦ä¸‹åˆ’çº¿çš„æ ‡è¯†ç¬¦",
			input:    "user_name test_case",
			expected: []string{"user_name", "test_case"},
		},
		{
			name:     "å¸¦è¿å­—ç¬¦çš„æ ‡è¯†ç¬¦",
			input:    "go-redis redis-cli",
			expected: []string{"go-redis", "redis-cli"},
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			result := tokenize(tt.input)
			if !compareStringSlices(result, tt.expected) {
				t.Errorf("tokenize(%q) = %v, want %v", tt.input, result, tt.expected)
			}
		})
	}
}

// æ€§èƒ½æµ‹è¯•
func BenchmarkTokenize(b *testing.B) {
	input := "Hello World ä½ å¥½ä¸–ç•Œ 1234567890"
	for i := 0; i < b.N; i++ {
		tokenize(input)
	}
}

// è¾…åŠ©å‡½æ•°ï¼šæ¯”è¾ƒå­—ç¬¦ä¸²åˆ‡ç‰‡
func compareStringSlices(a, b []string) bool {
	if len(a) != len(b) {
		return false
	}

	// åˆ›å»ºæ˜ å°„æ¥æ¯”è¾ƒ
	mapA := make(map[string]int)
	mapB := make(map[string]int)

	for _, s := range a {
		mapA[s]++
	}
	for _, s := range b {
		mapB[s]++
	}

	if len(mapA) != len(mapB) {
		return false
	}

	for k, v := range mapA {
		if mapB[k] != v {
			return false
		}
	}

	return true
}

// è¾¹ç¼˜æƒ…å†µæµ‹è¯•
func TestEdgeCases(t *testing.T) {
	t.Run("è¶…é•¿å­—ç¬¦ä¸²", func(t *testing.T) {
		// åˆ›å»ºä¸€ä¸ªè¶…é•¿çš„å­—ç¬¦ä¸²
		longString := ""
		for i := 0; i < 10000; i++ {
			longString += "a"
		}

		result := tokenize(longString)
		if len(result) == 0 {
			t.Error("è¶…é•¿å­—ç¬¦ä¸²åº”è¯¥è‡³å°‘è¿”å›ä¸€ä¸ªç»“æœ")
		}
	})

	t.Run("Unicodeè¾¹ç•Œ", func(t *testing.T) {
		// æµ‹è¯•Unicodeè¾¹ç•Œå­—ç¬¦
		boundaryChars := []rune{
			0x4DFF, // ä¸­æ–‡å­—ç¬¦èŒƒå›´ä¹‹å‰
			0x4E00, // ä¸­æ–‡å­—ç¬¦èŒƒå›´å¼€å§‹
			0x9FFF, // ä¸­æ–‡å­—ç¬¦èŒƒå›´ç»“æŸ
			0xA000, // ä¸­æ–‡å­—ç¬¦èŒƒå›´ä¹‹å
		}

		for _, char := range boundaryChars {
			input := string(char)
			result := tokenize(input)
			// åªåº”è¯¥ç´¢å¼•ä¸­æ–‡å­—ç¬¦èŒƒå›´å†…çš„å­—ç¬¦
			if char >= 0x4E00 && char <= 0x9FFF {
				if len(result) == 0 {
					t.Errorf("ä¸­æ–‡å­—ç¬¦ %U åº”è¯¥è¢«ç´¢å¼•", char)
				}
			} else {
				if len(result) > 0 {
					t.Errorf("éä¸­æ–‡å­—ç¬¦ %U ä¸åº”è¯¥è¢«ç´¢å¼•", char)
				}
			}
		}
	})

	t.Run("ç‰¹æ®ŠUnicodeå­—ç¬¦", func(t *testing.T) {
		// æµ‹è¯•å„ç§ç‰¹æ®ŠUnicodeå­—ç¬¦
		specialChars := []string{
			"Hello\u0000World", // ç©ºå­—ç¬¦
			"Hello\u0001World", // æ§åˆ¶å­—ç¬¦
			"Hello\u00A0World", // ä¸é—´æ–­ç©ºæ ¼
			"Hello\u200BWorld", // é›¶å®½ç©ºæ ¼
			"Hello\uFEFFWorld", // å­—èŠ‚é¡ºåºæ ‡è®°
		}

		for _, input := range specialChars {
			result := tokenize(input)
			// åº”è¯¥èƒ½æ­£ç¡®å¤„ç†ç‰¹æ®Šå­—ç¬¦
			if len(result) == 0 {
				t.Errorf("ç‰¹æ®Šå­—ç¬¦å­—ç¬¦ä¸²åº”è¯¥è¿”å›ç»“æœ: %q", input)
			}
		}
	})

	t.Run("æ•°å­—å¤„ç†", func(t *testing.T) {
		// æµ‹è¯•æ•°å­—å¤„ç†
		numberTests := []struct {
			input    string
			expected bool
		}{
			{"123", true},      // è¿ç»­æ•°å­—åº”è¯¥è¢«ç´¢å¼•
			{"1.2.3", true},    // å¸¦ç‚¹çš„ç‰ˆæœ¬å·åº”è¯¥è¢«ç´¢å¼•
			{"go-1.18", true},  // å¸¦è¿å­—ç¬¦çš„ç‰ˆæœ¬å·åº”è¯¥è¢«ç´¢å¼•
			{"user_123", true}, // å¸¦ä¸‹åˆ’çº¿çš„æ ‡è¯†ç¬¦åº”è¯¥è¢«ç´¢å¼•
		}

		for _, tt := range numberTests {
			result := tokenize(tt.input)
			hasExpected := false
			for _, word := range result {
				// æ£€æŸ¥æ˜¯å¦åŒ…å«æ•°å­—æˆ–ç‰ˆæœ¬å·æ¨¡å¼
				if strings.Contains(word, "123") || strings.Contains(word, "1.18") ||
					strings.Contains(word, "1.2.3") || strings.Contains(word, "user_123") {
					hasExpected = true
					break
				}
			}
			if hasExpected != tt.expected {
				t.Errorf("æ•°å­—å¤„ç† %s çš„ç»“æœä¸æ­£ç¡®: got %v, want %v, åˆ†è¯ç»“æœ: %v", tt.input, hasExpected, tt.expected, result)
			}
		}
	})
}

// æµ‹è¯•å¸¸é‡å®šä¹‰
func TestConstants(t *testing.T) {
	t.Run("æƒé‡å¸¸é‡", func(t *testing.T) {
		if WeightTitle != 10.0 {
			t.Errorf("æ ‡é¢˜æƒé‡åº”è¯¥æ˜¯ 10.0ï¼Œå®é™…æ˜¯ %f", WeightTitle)
		}
		if WeightContent != 1.0 {
			t.Errorf("å†…å®¹æƒé‡åº”è¯¥æ˜¯ 1.0ï¼Œå®é™…æ˜¯ %f", WeightContent)
		}
	})

	t.Run("Keyå‰ç¼€å¸¸é‡", func(t *testing.T) {
		if KeyPrefixArticle != "search:article:" {
			t.Errorf("æ–‡ç« Keyå‰ç¼€åº”è¯¥æ˜¯ 'search:article:'ï¼Œå®é™…æ˜¯ '%s'", KeyPrefixArticle)
		}
		if KeyPrefixIndex != "search:index:" {
			t.Errorf("ç´¢å¼•Keyå‰ç¼€åº”è¯¥æ˜¯ 'search:index:'ï¼Œå®é™…æ˜¯ '%s'", KeyPrefixIndex)
		}
		if KeyPrefixWords != "search:words:" {
			t.Errorf("è¯æ¡Keyå‰ç¼€åº”è¯¥æ˜¯ 'search:words:'ï¼Œå®é™…æ˜¯ '%s'", KeyPrefixWords)
		}
	})

	t.Run("ç¼“å­˜TTL", func(t *testing.T) {
		if ResultCacheTTL != 10*time.Minute {
			t.Errorf("ç»“æœç¼“å­˜TTLåº”è¯¥æ˜¯ 10åˆ†é’Ÿï¼Œå®é™…æ˜¯ %v", ResultCacheTTL)
		}
	})
}

// æµ‹è¯•æ­£åˆ™è¡¨è¾¾å¼
func TestRegexPatterns(t *testing.T) {
	t.Run("HTMLæ ‡ç­¾æ­£åˆ™", func(t *testing.T) {
		testCases := []struct {
			input    string
			expected string
		}{
			{"<h1>Hello</h1>", "Hello"},
			{"<p>ä¸–ç•Œ</p>", "ä¸–ç•Œ"},
			{"<div class='test'>Content</div>", "Content"},
			{"No tags here", "No tags here"},
		}

		for _, tc := range testCases {
			result := reHTMLTags.ReplaceAllString(tc.input, "")
			if result != tc.expected {
				t.Errorf("HTMLæ ‡ç­¾æ¸…ç†å¤±è´¥: è¾“å…¥ '%s', æœŸæœ› '%s', å®é™… '%s'", tc.input, tc.expected, result)
			}
		}
	})

	t.Run("ä¸­æ–‡å­—ç¬¦æ­£åˆ™", func(t *testing.T) {
		testCases := []struct {
			input       string
			shouldMatch bool
		}{
			{"ä½ ", true},
			{"å¥½", true},
			{"a", false},
			{"1", false},
			{"ğŸŒ", false},
		}

		for _, tc := range testCases {
			matches := reChineseChars.MatchString(tc.input)
			if matches != tc.shouldMatch {
				t.Errorf("ä¸­æ–‡å­—ç¬¦åŒ¹é…å¤±è´¥: è¾“å…¥ '%s', æœŸæœ›åŒ¹é… %v, å®é™…åŒ¹é… %v", tc.input, tc.shouldMatch, matches)
			}
		}
	})

	t.Run("å­—æ¯æ•°å­—æ­£åˆ™", func(t *testing.T) {
		testCases := []struct {
			input       string
			shouldMatch bool
		}{
			{"hello", true},
			{"123", true},
			{"go-1.18", true},
			{"user_name", true},
			{"ä½ å¥½", false},
			{"@#$", false},
		}

		for _, tc := range testCases {
			matches := reAlphanumeric.MatchString(tc.input)
			if matches != tc.shouldMatch {
				t.Errorf("å­—æ¯æ•°å­—åŒ¹é…å¤±è´¥: è¾“å…¥ '%s', æœŸæœ›åŒ¹é… %v, å®é™…åŒ¹é… %v", tc.input, tc.shouldMatch, matches)
			}
		}
	})
}
